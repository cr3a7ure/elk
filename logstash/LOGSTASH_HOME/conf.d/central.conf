input {
	beats {
		port => 5044
	#	type => "access.feature"
       		client_inactivity_timeout => 3600
	}
}

filter {
	# orders the input data into general fields. 
	grok {
	    patterns_dir => ["/etc/logstash/conf.d/patterns"]
		#patterns_dir => ["C:/Users/waeber/elk/logstash/LOGSTASH_HOME/conf.d/patterns"]
	    match => { "message" => "%{SWISSBIBLOG}" }
		tag_on_failure => [ "_message_parse_failure" ]
	}
	
	# reformats the date and removes the old timestamp field.
	date {
		match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
		target => "@timestamp"
		remove_field => [ "timestamp" ]
    	}

	# these are duplicated requests to build facet hierarchies and are not needed.
	if ([request] == "/AJAX/JSON/") {
		drop { }
	}

	# removes events without useragent. These are all actions not taken by users.
	if ([useragent] =~ /-/) {
       		drop { }
	}
	
	# filters out a few types of request which happen a lot but add no interesting information
    if ([message] =~ /(the\+art\+of\+computer\+programming)|(\/themes)|(^"-" - - )|(GET \/apple-touch-icon)|(GET \/favicon.ico)|(GET \/\?lng)|(GET \/" 200 19698 "-" "-")|(\/Cover\/Show)/) {
       		drop { }
    }
	
	# remove fields with just a '-' in it. This way kibana can more easily deal with not existing fields.
	if ([responsesize] =~ /-/) {
		mutate {
			remove_field => [ "responsesize" ]
		}
	}
	
	if ([referrer] =~ /-/) {
		mutate {
			remove_field => [ "referrer" ]
		}
	}

	if ([forwardip] =~ /-/) {
		mutate {
			remove_field => [ "forwardip" ]
		}
	}
	
	# sometimes two forward ips are in a request. these are separated for further processing. This way both ips are available in an array and can be used in kibana.
	if ([session] =~ /-/) {
		mutate {
			remove_field => [ "session" ]
		}
	}
	
	# some fields have two ips separated by comma, pack them into an arry for geoip to not throw an error
	# however currently they are not actually processed. 
	# unknown why they are not processed and unknown why there are two IPs in the first place.
	if ([forwardip] =~ /,/) {
		mutate {
			gsub => [ "forwardip", " ", "" ]
			split => { "forwardip" => "," }
		}
	}

	# Looks up the ip in the database and creates fields with associated data. Location is a geo-point hash which alows kibana to plot the data into maps.
	if ([forwardip] =~ /^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$/) {
		geoip {
			source => "forwardip"
			#database => "C:/Users/waeber/Desktop/logstash-5.3.3/vendor/bundle/jruby/1.9/gems/logstash-filter-geoip-4.0.4-java/vendor/GeoLite2-City.mmdb"
			database => "/etc/logstash/geoip/GeoLite2-City.mmdb"

			target => "geoip"
			fields => ["city_name", "country_name", "location"]
			add_tag => [ "apache-geoip" ]
			tag_on_failure => ["_geoip_lookup_failure"]
		}
	}
	
	# looks up the library code in dictionary and puts the name into library_name
	# requires manual update if new libraries are added to swissbib
	if ([library_code]) {
		translate {
			field => "library_code"
			destination => "library_name"
			dictionary_path => "/etc/logstash/conf.d/dictionaries/swissbib_libraries.yml"
			exact => true
		}
	}
	
	# analyzes the user agent of the request and creates a user field
	# 
	# https://www.elastic.co/guide/en/logstash/current/plugins-filters-useragent.html
	# https://de.wikipedia.org/wiki/User_Agent
	if ([useragent]){
		useragent {
			source => [ "useragent" ]
			target => [ "userdata" ]
		}
	}
	
	# remove some fields whith information we don't really need
	# the add_field is required as there is a documented bug which makes the removal impossible otherwise.
	# leaves userdata.device, userdata.name & userdata.os_name.
	if ([userdata]){
		mutate {
			add_field => { "[userdata][os_major]" => "os_major_version" }
			remove_field => ["[userdata][os_major]", "[userdata][os_minor]", "[userdata][os]", "[userdata][patch]", "[userdata][major]", "[userdata][minor]", "[userdata][build]" ]
		}
	}

	# process the request fields. 
	if ([request]) {
		mutate {
			# keep adding fields and manipulating fields separate as they might not work otherwise.
			add_field => { "request_split" => "%{request}"}
		}
		
		mutate {
			# replace slashes with spaces to easily remove the leading slash and then split the path.
			gsub => [ "request_split", "/", " " ]
			strip => [ "request_split" ]
			split => { "request_split" => " "}
		}
		
		# move each request part into a separat field for better searching and visualizing.
		if ([request] =~ /^\/[\w.-]+$/) {
			grok {
				id => "single_request_parse"
				match => { "request" => "/\/%{USER:request_root}" }
				tag_on_failure => [ "_single_request_parse_failure" ]
			}
		}
		if ([request] =~ /^\/[\w.-]+\/[\w.-]+$/) {
			grok {
				id => "double_request_parse"
				match => { "request" => "/\/%{USER:request_root}\/%{USER:request_middle}" }
				tag_on_failure => [ "_double_request_parse_failure" ]
			}
		}
		if ([request] =~ /^\/[\w.-]+\/[\w.-]+\/[\w.-]+$/) {
			grok {
				id => "tripple_request_parse"
				match => { "request" => "/\/%{USER:request_root}\/%{USER:request_middle}\/%{USER:request_end}" }
				tag_on_failure => [ "_tripple_request_parse_failure" ]
			}
		}
		
		# searches for holding requests and extracts the holding identifiers.
		# and stores the value in a new field 'library_code'
		if ([request_root] == "Holdings") {
			grok {
				id => "holdings_grok"
				match => { "request_end" => "%{WORD:library_code}" }
				tag_on_failure => [ "_holding_parse_failure" ]
			}	
		}
	}
	
	if ([requestparam]) {
		mutate {
			add_field => { "requestparam_split" => "%{requestparam}"}			
		}
		mutate {
			split => { "requestparam_split" => "&"}
		}
	
		urldecode {
			all_fields => true
			charset => "UTF-8"
			tag_on_failure => ["_url_decode_failure"]
		}
	
		# parses request params and puts each assignment into a field.
		kv {
			source => "requestparam_split"
			target => "search_params"
			# whitlist of all included fields. if this is removed hundreds of fields are created.
			include_keys => [ "lookfor", "type", "sort", "filter", "bool", "edit", 
								"enitityID", "expandlib", "facet", "join", "limit", "originalSort", 
								"page", "PublicationDatefrom", "PublicationDateto", "publishDatefrom", 
								"publishDateto", "style", "view" ]
			# remove numbers to ensure that everything is mapped to the same field. 
			remove_char_key => "\[\]0123456789"
			transform_key => "lowercase"
			field_split => "?"
			value_split => "="
		}

		mutate {
			rename => { "[search_params][PublicationDateto]" => "[search_params][publishdateto]" }
			rename => { "[search_params][PublicationDatefrom]" => "[search_params][publishdatefrom]" }
		}

		if ([search_params][expandlib]) {
			translate {
				field => "[search_params][expandlib]"
				destination => "library_name"
				dictionary_path => "/etc/logstash/conf.d/dictionaries/swissbib_libraries.yml"
				exact => true
			}	
		}
		
		# expand facet filters into fields:
		if ([search_params][filter]) {
			kv {
				source => "[search_params][filter]"
				target => "filter_params"
				remove_char_key => "~-"
				remove_char_value => "\""
				transform_key => "lowercase"
				transform_value => "lowercase"
				value_split => ":"
			}
			# rename filters to more readable form and more unified between platforms.
			mutate {
				# Online Available?
				rename => { "[filter_params][filter_str_mv]" => "[filter_params][online]" }
				rename => { "[filter_params][e_institution_str_mv]" => "[filter_params][online]" }
				# Format
				rename => { "[filter_params][contenttype]" => "[filter_params][format]" }
				rename => { "[filter_params][format_hierarchy_str_mv]" => "[filter_params][format]" }
				rename => { "[filter_params][format_str_mv]" => "[filter_params][format]" }
				# Genre Form
				rename => { "[filter_params][navsubform]" => "[filter_params][genre_form]" }
				# Subject
				rename => { "[filter_params][navsub_orange]" => "[filter_params][subject]" }
				rename => { "[filter_params][navsub_jus]" => "[filter_params][subject]" }
				rename => { "[filter_params][navsub_green]" => "[filter_params][subject]" }
				rename => { "[filter_params][subjectterms]" => "[filter_params][subject]" }
				# Author
				rename => { "[filter_params][navauthor_full]" => "[filter_params][author]" }
				rename => { "[filter_params][navauthor_orange]" => "[filter_params][author]" }
				# Publication Date				
				rename => { "[filter_params][publishdate]" => "[filter_params][publicationdate]" }
				# Jus Classification
				rename => { "[filter_params][navdrsys]" => "[filter_params][jus_classification]" }
				rename => { "[filter_params][navdrsys_gen]" => "[filter_params][jus_classification]" }
				# Libraries
				rename => { "[filter_params][mylibraries]" => "[filter_params][library]" }
				rename => { "[filter_params][institution]" => "[filter_params][library]" }
				rename => { "[filter_params][union]" => "[filter_params][library]" }
				# Geography
				rename => { "[filter_params][navsub_geofull]" => "[filter_params][geography]" }											
			}
			
			if ([filter_params][library]) {
				translate {
					field => "[filter_params][library]"
					destination => "library_name"
					dictionary_path => "/etc/logstash/conf.d/dictionaries/swissbib_libraries.yml"
					exact => true
				}	
			}

			# rename shortened language codes.
			if ([filter_params][language]) {
				translate {
					field => "[filter_params][language]"
					destination => "[filter_params][language]"
					override => true
					exact => true
					dictionary_path => "/etc/logstash/conf.d/dictionaries/iso_639_2_language_codes.yml"
				}
			}
		}
	
		#parse search strings
		if ([search_params][lookfor]) {
			# replace all + and ,.
			mutate {
				gsub => [ "[search_params][lookfor]", "\+", " " ]
				gsub => [ "[search_params][lookfor]", ",", "" ]
			}
			
			# Adds a copy of the search field.
			mutate {
				add_field => { "[search_params][search]" => "%{[search_params][lookfor]}"}
			}
			# splits the search field into an array.
			mutate {
				split => { "[search_params][search]" => " " }
			}
			
			# count the number of words in a search.
			if ([search_params][search]) {
				mutate {
					add_field => { "[search_params][words_in_search]" => "" }
				}
				ruby {
					code => "event.set('[search_params][words_in_search]', event.get('[search_params][search]').length)"
				}
			}
		}
	}
	
	# detects and translates hosts
    if ([host] =~ /sb-uvf1|sb-uvf2|sb-uvf3/) {
		mutate {
			add_field => {"sourcetype" => "presentationgreen" } 
		}
    } 

    if ([host] =~ /sb-uvf9|sb-uvf10|sb-uvf11/) {
		mutate {
			add_field => {"sourcetype" => "presentationbb" } 
		}
    } 

    if ([host] =~ /sb-uvf5/) {
		mutate {
			add_field => {"sourcetype" => "presentationjus" } 
		}
    }
}

output {
    if ([sourcetype] == "presentationgreen") {
		elasticsearch { 
			hosts => ["sb-uesl1.swissbib.unibas.ch:8080"]
			#template => "C:/Users/waeber/elk/logstash/LOGSTASH_HOME/conf.d/es_template/apache_template.json"
			template => "/etc/logstash/conf.d/es_template/apache_template.json"

			template_name => "apache_template"
			template_overwrite => true
			index => "swissbib-v2-green-%{+YYYY}"
			document_type => "logs"
		}
    }

    if ([sourcetype] == "presentationbb") {
		elasticsearch { 
			hosts => ["sb-uesl1.swissbib.unibas.ch:8080"]
			#template => "C:/Users/waeber/elk/logstash/LOGSTASH_HOME/conf.d/es_template/apache_template.json"
			template => "/etc/logstash/conf.d/es_template/apache_template.json"
			template_name => "apache_template"
			template_overwrite => true
			index => "swissbib-v2-bb-%{+YYYY}"
			document_type => "logs"
		}
    }

    if ([sourcetype] == "presentationjus") {
		elasticsearch { 
			hosts => ["sb-uesl1.swissbib.unibas.ch:8080"]
			#template => "C:/Users/waeber/elk/logstash/LOGSTASH_HOME/conf.d/es_template/apache_template.json"
			template => "/etc/logstash/conf.d/es_template/apache_template.json"
			template_name => "apache_template"
			template_overwrite => true
			index => "swissbib-v2-jus-%{+YYYY}"
			document_type => "logs"
		}
    }
}
